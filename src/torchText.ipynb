{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torchtext import data\n",
    "\n",
    "SEED = 1234\n",
    "\n",
    "torch.manual_seed(SEED)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "\n",
    "TEXT = data.Field(tokenize = 'spacy')\n",
    "LABEL = data.LabelField(dtype = torch.float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      ".data\\imdb\\aclImdb_v1.tar.gz:   0%|          | 0.00/84.1M [00:00<?, ?B/s]downloading aclImdb_v1.tar.gz\n",
      ".data\\imdb\\aclImdb_v1.tar.gz: 100%|██████████| 84.1M/84.1M [00:06<00:00, 12.9MB/s]\n"
     ]
    }
   ],
   "source": [
    "from torchtext import datasets\n",
    "train_data, test_data = datasets.IMDB.splits(TEXT, LABEL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torchtext.datasets.imdb.IMDB at 0x11d131bc688>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<torchtext.datasets.imdb.IMDB object at 0x0000011D131BC688>\n"
     ]
    }
   ],
   "source": [
    "print(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "When using a dict to specify fields with a csv file,skip_header must be False andthe file must have a header.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-6-f5b50f0f9b64>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      6\u001b[0m                                         \u001b[0mformat\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'csv'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m                                         \u001b[0mfields\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfields\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 8\u001b[1;33m                                         \u001b[0mskip_header\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      9\u001b[0m )\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\torchtext\\data\\dataset.py\u001b[0m in \u001b[0;36msplits\u001b[1;34m(cls, path, root, train, validation, test, **kwargs)\u001b[0m\n\u001b[0;32m     76\u001b[0m             \u001b[0mpath\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcls\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdownload\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mroot\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     77\u001b[0m         train_data = None if train is None else cls(\n\u001b[1;32m---> 78\u001b[1;33m             os.path.join(path, train), **kwargs)\n\u001b[0m\u001b[0;32m     79\u001b[0m         val_data = None if validation is None else cls(\n\u001b[0;32m     80\u001b[0m             os.path.join(path, validation), **kwargs)\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\torchtext\\data\\dataset.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, path, format, fields, skip_header, csv_reader_params, **kwargs)\u001b[0m\n\u001b[0;32m    261\u001b[0m                     raise ValueError('When using a dict to specify fields with a {} file,'\n\u001b[0;32m    262\u001b[0m                                      \u001b[1;34m'skip_header must be False and'\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 263\u001b[1;33m                                      'the file must have a header.'.format(format))\n\u001b[0m\u001b[0;32m    264\u001b[0m                 \u001b[0mheader\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mreader\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    265\u001b[0m                 \u001b[0mfield_to_index\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m{\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mheader\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mf\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mfields\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: When using a dict to specify fields with a csv file,skip_header must be False andthe file must have a header."
     ]
    }
   ],
   "source": [
    "fields = {'text': ('t', TEXT), 'label': ('l', LABEL)}\n",
    "train_data, test_data = data.TabularDataset.splits(\n",
    "                                        path = '../data',\n",
    "                                        train = 'news.csv',\n",
    "                                        test = 'news.csv',\n",
    "                                        format = 'csv',\n",
    "                                        fields = fields,\n",
    "                                        skip_header = True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas\n",
    "df = pd.read_csv(\"../data/news.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop(['Unnamed: 0'], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_json('news.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data, test_data = data.TabularDataset.splits(\n",
    "                            path = '',\n",
    "                            train = 'news.json',\n",
    "                            test = 'news.json',\n",
    "                            format = 'json',\n",
    "                            fields = fields\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# New Stuff\n",
    "from torchtext.data import Field, TabularDataset, BucketIterator\n",
    "import spacy\n",
    "import torch\n",
    "\n",
    "torch.backends.cudnn.deterministic = True\n",
    "\n",
    "# spacy_en = spacy.load('en')\n",
    "# def tokenize(text)z:\n",
    "#     return [token.text for token in spacy_en.tokenizer(text)]\n",
    "\n",
    "title = Field(sequential=True, use_vocab=True, tokenize='spacy', lower=True)\n",
    "text = Field(sequential=True, use_vocab=True, tokenize='spacy', lower=True)\n",
    "label = Field(sequential=False, use_vocab=False)\n",
    "\n",
    "fields = {'title': ('title', title), 'text': ('text', text), 'label': ('label', label)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Num of training:  6335\nNum of testing:  6335\n"
     ]
    }
   ],
   "source": [
    "train_data, test_data = TabularDataset.splits(\n",
    "    path='',\n",
    "    train='news.csv',\n",
    "    test='news.csv',\n",
    "    format='csv',\n",
    "    fields=fields)\n",
    "print(\"Num of training: \", len(train_data))\n",
    "print(\"Num of testing: \", len(test_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Num of training:  3563\nNum of testing:  1188\nNum of testing:  6335\n"
     ]
    }
   ],
   "source": [
    "train_data, validation_data = train_data.split(split_ratio=0.75)\n",
    "print(\"Num of training: \", len(train_data))\n",
    "print(\"Num of testing: \", len(validation_data))\n",
    "print(\"Num of testing: \", len(test_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "dict_keys(['title', 'text', 'label'])\ndict_values([['you', 'can', 'smell', 'hillary’s', 'fear'], ['daniel', 'greenfield,', 'a', 'shillman', 'journalism', 'fellow', 'at', 'the', 'freedom', 'center,', 'is', 'a', 'new', 'york', 'writer', 'focusing', 'on', 'radical', 'islam.', 'in', 'the', 'final', 'stretch', 'of', 'the', 'election,', 'hillary', 'rodham', 'clinton', 'has', 'gone', 'to', 'war', 'with', 'the', 'fbi.', 'the', 'word', '“unprecedented”', 'has', 'been', 'thrown', 'around', 'so', 'often', 'this', 'election', 'that', 'it', 'ought', 'to', 'be', 'retired.', 'but', 'it’s', 'still', 'unprecedented', 'for', 'the', 'nominee', 'of', 'a', 'major', 'political', 'party', 'to', 'go', 'war', 'with', 'the', 'fbi.', 'but', 'that’s', 'exactly', 'what', 'hillary', 'and', 'her', 'people', 'have', 'done.', 'coma', 'patients', 'just', 'waking', 'up', 'now', 'and', 'watching', 'an', 'hour', 'of', 'cnn', 'from', 'their', 'hospital', 'beds', 'would', 'assume', 'that', 'fbi', 'director', 'james', 'comey', 'is', 'hillary’s', 'opponent', 'in', 'this', 'election.', 'the', 'fbi', 'is', 'under', 'attack', 'by', 'everyone', 'from', 'obama', 'to', 'cnn.', 'hillary’s', 'people', 'have', 'circulated', 'a', 'letter', 'attacking', 'comey.', 'there', 'are', 'currently', 'more', 'media', 'hit', 'pieces', 'lambasting', 'him', 'than', 'targeting', 'trump.', 'it', 'wouldn’t', 'be', 'too', 'surprising', 'if', 'the', 'clintons', 'or', 'their', 'allies', 'were', 'to', 'start', 'running', 'attack', 'ads', 'against', 'the', 'fbi.', 'the', 'fbi’s', 'leadership', 'is', 'being', 'warned', 'that', 'the', 'entire', 'left-wing', 'establishment', 'will', 'form', 'a', 'lynch', 'mob', 'if', 'they', 'continue', 'going', 'after', 'hillary.', 'and', 'the', 'fbi’s', 'credibility', 'is', 'being', 'attacked', 'by', 'the', 'media', 'and', 'the', 'democrats', 'to', 'preemptively', 'head', 'off', 'the', 'results', 'of', 'the', 'investigation', 'of', 'the', 'clinton', 'foundation', 'and', 'hillary', 'clinton.', 'the', 'covert', 'struggle', 'between', 'fbi', 'agents', 'and', 'obama’s', 'doj', 'people', 'has', 'gone', 'explosively', 'public.', 'the', 'new', 'york', 'times', 'has', 'compared', 'comey', 'to', 'j.', 'edgar', 'hoover.', 'its', 'bizarre', 'headline,', '“james', 'comey', 'role', 'recalls', 'hoover’s', 'fbi,', 'fairly', 'or', 'not”', 'practically', 'admits', 'up', 'front', 'that', 'it’s', 'spouting', 'nonsense.', 'the', 'boston', 'globe', 'has', 'published', 'a', 'column', 'calling', 'for', 'comey’s', 'resignation.', 'not', 'to', 'be', 'outdone,', 'time', 'has', 'an', 'editorial', 'claiming', 'that', 'the', 'scandal', 'is', 'really', 'an', 'attack', 'on', 'all', 'women.', 'james', 'carville', 'appeared', 'on', 'msnbc', 'to', 'remind', 'everyone', 'that', 'he', 'was', 'still', 'alive', 'and', 'insane.', 'he', 'accused', 'comey', 'of', 'coordinating', 'with', 'house', 'republicans', 'and', 'the', 'kgb.', 'and', 'you', 'thought', 'the', '“vast', 'right', 'wing', 'conspiracy”', 'was', 'a', 'stretch.', 'countless', 'media', 'stories', 'charge', 'comey', 'with', 'violating', 'procedure.', 'do', 'you', 'know', 'what’s', 'a', 'procedural', 'violation?', 'emailing', 'classified', 'information', 'stored', 'on', 'your', 'bathroom', 'server.', 'senator', 'harry', 'reid', 'has', 'sent', 'comey', 'a', 'letter', 'accusing', 'him', 'of', 'violating', 'the', 'hatch', 'act.', 'the', 'hatch', 'act', 'is', 'a', 'nice', 'idea', 'that', 'has', 'as', 'much', 'relevance', 'in', 'the', 'age', 'of', 'obama', 'as', 'the', 'tenth', 'amendment.', 'but', 'the', 'cable', 'news', 'spectrum', 'quickly', 'filled', 'with', 'media', 'hacks', 'glancing', 'at', 'the', 'wikipedia', 'article', 'on', 'the', 'hatch', 'act', 'under', 'the', 'table', 'while', 'accusing', 'the', 'fbi', 'director', 'of', 'one', 'of', 'the', 'most', 'awkward', 'conspiracies', 'against', 'hillary', 'ever.', 'if', 'james', 'comey', 'is', 'really', 'out', 'to', 'hurt', 'hillary,', 'he', 'picked', 'one', 'hell', 'of', 'a', 'strange', 'way', 'to', 'do', 'it.', 'not', 'too', 'long', 'ago', 'democrats', 'were', 'breathing', 'a', 'sigh', 'of', 'relief', 'when', 'he', 'gave', 'hillary', 'clinton', 'a', 'pass', 'in', 'a', 'prominent', 'public', 'statement.', 'if', 'he', 'really', 'were', 'out', 'to', 'elect', 'trump', 'by', 'keeping', 'the', 'email', 'scandal', 'going,', 'why', 'did', 'he', 'trash', 'the', 'investigation?', 'was', 'he', 'on', 'the', 'payroll', 'of', 'house', 'republicans', 'and', 'the', 'kgb', 'back', 'then', 'and', 'playing', 'it', 'coy', 'or', 'was', 'it', 'a', 'sudden', 'development', 'where', 'vladimir', 'putin', 'and', 'paul', 'ryan', 'talked', 'him', 'into', 'taking', 'a', 'look', 'at', 'anthony', 'weiner’s', 'computer?', 'either', 'comey', 'is', 'the', 'most', 'cunning', 'fbi', 'director', 'that', 'ever', 'lived', 'or', 'he’s', 'just', 'awkwardly', 'trying', 'to', 'navigate', 'a', 'political', 'mess', 'that', 'has', 'trapped', 'him', 'between', 'a', 'doj', 'leadership', 'whose', 'political', 'futures', 'are', 'tied', 'to', 'hillary’s', 'victory', 'and', 'his', 'own', 'bureau', 'whose', 'apolitical', 'agents', 'just', 'want', 'to', 'be', 'allowed', 'to', 'do', 'their', 'jobs.', 'the', 'only', 'truly', 'mysterious', 'thing', 'is', 'why', 'hillary', 'and', 'her', 'associates', 'decided', 'to', 'go', 'to', 'war', 'with', 'a', 'respected', 'federal', 'agency.', 'most', 'americans', 'like', 'the', 'fbi', 'while', 'hillary', 'clinton', 'enjoys', 'a', '60%', 'unfavorable', 'rating.', 'and', 'it’s', 'an', 'interesting', 'question.', 'hillary’s', 'old', 'strategy', 'was', 'to', 'lie', 'and', 'deny', 'that', 'the', 'fbi', 'even', 'had', 'a', 'criminal', 'investigation', 'underway.', 'instead', 'her', 'associates', 'insisted', 'that', 'it', 'was', 'a', 'security', 'review.', 'the', 'fbi', 'corrected', 'her', 'and', 'she', 'shrugged', 'it', 'off.', 'but', 'the', 'old', 'breezy', 'denial', 'approach', 'has', 'given', 'way', 'to', 'a', 'savage', 'assault', 'on', 'the', 'fbi.', 'pretending', 'that', 'nothing', 'was', 'wrong', 'was', 'a', 'bad', 'strategy,', 'but', 'it', 'was', 'a', 'better', 'one', 'that', 'picking', 'a', 'fight', 'with', 'the', 'fbi', 'while', 'lunatic', 'clinton', 'associates', 'try', 'to', 'claim', 'that', 'the', 'fbi', 'is', 'really', 'the', 'kgb.', 'there', 'are', 'two', 'possible', 'explanations.', 'hillary', 'clinton', 'might', 'be', 'arrogant', 'enough', 'to', 'lash', 'out', 'at', 'the', 'fbi', 'now', 'that', 'she', 'believes', 'that', 'victory', 'is', 'near.', 'the', 'same', 'kind', 'of', 'hubris', 'that', 'led', 'her', 'to', 'plan', 'her', 'victory', 'fireworks', 'display', 'could', 'lead', 'her', 'to', 'declare', 'a', 'war', 'on', 'the', 'fbi', 'for', 'irritating', 'her', 'during', 'the', 'final', 'miles', 'of', 'her', 'campaign.', 'but', 'the', 'other', 'explanation', 'is', 'that', 'her', 'people', 'panicked.', 'going', 'to', 'war', 'with', 'the', 'fbi', 'is', 'not', 'the', 'behavior', 'of', 'a', 'smart', 'and', 'focused', 'presidential', 'campaign.', 'it’s', 'an', 'act', 'of', 'desperation.', 'when', 'a', 'presidential', 'candidate', 'decides', 'that', 'her', 'only', 'option', 'is', 'to', 'try', 'and', 'destroy', 'the', 'credibility', 'of', 'the', 'fbi,', 'that’s', 'not', 'hubris,', 'it’s', 'fear', 'of', 'what', 'the', 'fbi', 'might', 'be', 'about', 'to', 'reveal', 'about', 'her.', 'during', 'the', 'original', 'fbi', 'investigation,', 'hillary', 'clinton', 'was', 'confident', 'that', 'she', 'could', 'ride', 'it', 'out.', 'and', 'she', 'had', 'good', 'reason', 'for', 'believing', 'that.', 'but', 'that', 'hillary', 'clinton', 'is', 'gone.', 'in', 'her', 'place', 'is', 'a', 'paranoid', 'wreck.', 'within', 'a', 'short', 'space', 'of', 'time', 'the', '“positive”', 'clinton', 'campaign', 'promising', 'to', 'unite', 'the', 'country', 'has', 'been', 'replaced', 'by', 'a', 'desperate', 'and', 'flailing', 'operation', 'that', 'has', 'focused', 'all', 'its', 'energy', 'on', 'fighting', 'the', 'fbi.', 'there’s', 'only', 'one', 'reason', 'for', 'such', 'bizarre', 'behavior.', 'the', 'clinton', 'campaign', 'has', 'decided', 'that', 'an', 'fbi', 'investigation', 'of', 'the', 'latest', 'batch', 'of', 'emails', 'poses', 'a', 'threat', 'to', 'its', 'survival.', 'and', 'so', 'it’s', 'gone', 'all', 'in', 'on', 'fighting', 'the', 'fbi.', 'it’s', 'an', 'unprecedented', 'step', 'born', 'of', 'fear.', 'it’s', 'hard', 'to', 'know', 'whether', 'that', 'fear', 'is', 'justified.', 'but', 'the', 'existence', 'of', 'that', 'fear', 'already', 'tells', 'us', 'a', 'whole', 'lot.', 'clinton', 'loyalists', 'rigged', 'the', 'old', 'investigation.', 'they', 'knew', 'the', 'outcome', 'ahead', 'of', 'time', 'as', 'well', 'as', 'they', 'knew', 'the', 'debate', 'questions.', 'now', 'suddenly', 'they', 'are', 'no', 'longer', 'in', 'control.', 'and', 'they', 'are', 'afraid.', 'you', 'can', 'smell', 'the', 'fear.', 'the', 'fbi', 'has', 'wiretaps', 'from', 'the', 'investigation', 'of', 'the', 'clinton', 'foundation.', 'it’s', 'finding', 'new', 'emails', 'all', 'the', 'time.', 'and', 'clintonworld', 'panicked.', 'the', 'spinmeisters', 'of', 'clintonworld', 'have', 'claimed', 'that', 'the', 'email', 'scandal', 'is', 'just', 'so', 'much', 'smoke', 'without', 'fire.', 'all', 'that’s', 'here', 'is', 'the', 'appearance', 'of', 'impropriety', 'without', 'any', 'of', 'the', 'substance.', 'but', 'this', 'isn’t', 'how', 'you', 'react', 'to', 'smoke.', 'it’s', 'how', 'you', 'respond', 'to', 'a', 'fire.', 'the', 'misguided', 'assault', 'on', 'the', 'fbi', 'tells', 'us', 'that', 'hillary', 'clinton', 'and', 'her', 'allies', 'are', 'afraid', 'of', 'a', 'revelation', 'bigger', 'than', 'the', 'fundamental', 'illegality', 'of', 'her', 'email', 'setup.', 'the', 'email', 'setup', 'was', 'a', 'preemptive', 'cover', 'up.', 'the', 'clinton', 'campaign', 'has', 'panicked', 'badly', 'out', 'of', 'the', 'belief,', 'right', 'or', 'wrong,', 'that', 'whatever', 'crime', 'the', 'illegal', 'setup', 'was', 'meant', 'to', 'cover', 'up', 'is', 'at', 'risk', 'of', 'being', 'exposed.', 'the', 'clintons', 'have', 'weathered', 'countless', 'scandals', 'over', 'the', 'years.', 'whatever', 'they', 'are', 'protecting', 'this', 'time', 'around', 'is', 'bigger', 'than', 'the', 'usual', 'corruption,', 'bribery,', 'sexual', 'assaults', 'and', 'abuses', 'of', 'power', 'that', 'have', 'followed', 'them', 'around', 'throughout', 'the', 'years.', 'this', 'is', 'bigger', 'and', 'more', 'damaging', 'than', 'any', 'of', 'the', 'allegations', 'that', 'have', 'already', 'come', 'out.', 'and', 'they', 'don’t', 'want', 'fbi', 'investigators', 'anywhere', 'near', 'it.', 'the', 'campaign', 'against', 'comey', 'is', 'pure', 'intimidation.', 'it’s', 'also', 'a', 'warning.', 'any', 'senior', 'fbi', 'people', 'who', 'value', 'their', 'careers', 'are', 'being', 'warned', 'to', 'stay', 'away.', 'the', 'democrats', 'are', 'closing', 'ranks', 'around', 'their', 'nominee', 'against', 'the', 'fbi.', 'it’s', 'an', 'ugly', 'and', 'unprecedented', 'scene.', 'it', 'may', 'also', 'be', 'their', 'last', 'stand.', 'hillary', 'clinton', 'has', 'awkwardly', 'wound', 'her', 'way', 'through', 'numerous', 'scandals', 'in', 'just', 'this', 'election', 'cycle.', 'but', 'she’s', 'never', 'shown', 'fear', 'or', 'desperation', 'before.', 'now', 'that', 'has', 'changed.', 'whatever', 'she', 'is', 'afraid', 'of,', 'it', 'lies', 'buried', 'in', 'her', 'emails', 'with', 'huma', 'abedin.', 'and', 'it', 'can', 'bring', 'her', 'down', 'like', 'nothing', 'else', 'has.'], 'FAKE'])\n"
     ]
    }
   ],
   "source": [
    "print(train_data[0].__dict__.keys())\n",
    "print(train_data[0].__dict__.values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_VOCAB_SIZE = 25000\n",
    "text.build_vocab(train_data, max_size=MAX_VOCAB_SIZE)\n",
    "title.build_vocab(train_data, max_size=MAX_VOCAB_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "output_type": "error",
     "ename": "NameError",
     "evalue": "name 'torch' is not defined",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-19-a025fff74aec>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mBATCH_SIZE\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m64\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mdevice\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'cuda'\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mis_available\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32melse\u001b[0m \u001b[1;34m'cpu'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m train_iterator, validation_iterator, test_iterator = BucketIterator.splits(\n",
      "\u001b[1;31mNameError\u001b[0m: name 'torch' is not defined"
     ]
    }
   ],
   "source": [
    "BATCH_SIZE = 64\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "train_iterator, validation_iterator, test_iterator = BucketIterator.splits(\n",
    "    (train_data, validation_data, test_data),\n",
    "    batch_size=BATCH_SIZE,\n",
    "    device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "output_type": "error",
     "ename": "AttributeError",
     "evalue": "'Field' object has no attribute 'vocab'",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-11-b96756896ac4>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mfor\u001b[0m \u001b[0mbatch\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mtrain_iterator\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtitle\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\torchtext\\data\\iterator.py\u001b[0m in \u001b[0;36m__iter__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    160\u001b[0m                     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    161\u001b[0m                         \u001b[0mminibatch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msort\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msort_key\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreverse\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 162\u001b[1;33m                 \u001b[1;32myield\u001b[0m \u001b[0mBatch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mminibatch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    163\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrepeat\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    164\u001b[0m                 \u001b[1;32mreturn\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\torchtext\\data\\batch.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, data, dataset, device)\u001b[0m\n\u001b[0;32m     34\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0mfield\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     35\u001b[0m                     \u001b[0mbatch\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mgetattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 36\u001b[1;33m                     \u001b[0msetattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfield\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprocess\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     37\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     38\u001b[0m     \u001b[1;33m@\u001b[0m\u001b[0mclassmethod\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\torchtext\\data\\field.py\u001b[0m in \u001b[0;36mprocess\u001b[1;34m(self, batch, device)\u001b[0m\n\u001b[0;32m    232\u001b[0m         \"\"\"\n\u001b[0;32m    233\u001b[0m         \u001b[0mpadded\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpad\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 234\u001b[1;33m         \u001b[0mtensor\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnumericalize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpadded\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    235\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mtensor\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    236\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\torchtext\\data\\field.py\u001b[0m in \u001b[0;36mnumericalize\u001b[1;34m(self, arr, device)\u001b[0m\n\u001b[0;32m    331\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0muse_vocab\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    332\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msequential\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 333\u001b[1;33m                 \u001b[0marr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvocab\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstoi\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mex\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mex\u001b[0m \u001b[1;32min\u001b[0m \u001b[0marr\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    334\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    335\u001b[0m                 \u001b[0marr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvocab\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstoi\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0marr\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\torchtext\\data\\field.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    331\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0muse_vocab\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    332\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msequential\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 333\u001b[1;33m                 \u001b[0marr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvocab\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstoi\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mex\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mex\u001b[0m \u001b[1;32min\u001b[0m \u001b[0marr\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    334\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    335\u001b[0m                 \u001b[0marr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvocab\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstoi\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0marr\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\torchtext\\data\\field.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    331\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0muse_vocab\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    332\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msequential\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 333\u001b[1;33m                 \u001b[0marr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvocab\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstoi\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mex\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mex\u001b[0m \u001b[1;32min\u001b[0m \u001b[0marr\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    334\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    335\u001b[0m                 \u001b[0marr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvocab\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstoi\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0marr\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'Field' object has no attribute 'vocab'"
     ]
    }
   ],
   "source": [
    "for batch in train_iterator:\n",
    "    print(batch.title)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.7.9 64-bit (conda)",
   "metadata": {
    "interpreter": {
     "hash": "1f307c3022c27ca4762c821a3aebb95f65fea64f739e5b86e4575fdd25133081"
    }
   }
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}