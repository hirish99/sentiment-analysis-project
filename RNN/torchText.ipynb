{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# New Stuff\n",
    "from torchtext.data import Field, TabularDataset, BucketIterator, LabelField\n",
    "import spacy\n",
    "import torch\n",
    "\n",
    "torch.backends.cudnn.deterministic = True\n",
    "\n",
    "# spacy_en = spacy.load('en')\n",
    "\n",
    "#     return [token.text for token in spacy_en.tokenizer(text)]\n",
    "\n",
    "title = Field(sequential=True, use_vocab=True, tokenize='spacy', lower=True)\n",
    "text = Field(sequential=True, use_vocab=True, tokenize='spacy', lower=True)\n",
    "label = LabelField(dtype=torch.float)\n",
    "\n",
    "fields = {'title': ('title', title), 'text': ('text', text), 'label': ('label', label)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Num of training:  6335\n"
     ]
    }
   ],
   "source": [
    "train_data = TabularDataset.splits(\n",
    "    path='../data',\n",
    "    train='news.csv',\n",
    "    # validation='news.csv',\n",
    "    # test='news.csv',\n",
    "    format='csv',\n",
    "    fields=fields)[0]\n",
    "print(\"Num of training: \", len(train_data))\n",
    "# print(\"Num of validation: \", len(validation_data))\n",
    "# print(\"Num of testing: \", len(test_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Num of training:  4118\nNum of validation:  1108\nNum of testing:  1109\n"
     ]
    }
   ],
   "source": [
    "train_data, validation_data = train_data.split(split_ratio=0.65)\n",
    "validation_data, test_data = validation_data.split(split_ratio=0.5)\n",
    "print(\"Num of training: \", len(train_data))\n",
    "print(\"Num of validation: \", len(validation_data))\n",
    "print(\"Num of testing: \", len(test_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "dict_keys(['title', 'text', 'label'])\ndict_values([['2nd', 'new', 'york', 'prison', 'worker', 'charged', 'in', 'killers', \"'\", 'escape'], ['plattsburgh', ',', 'new', 'york', '(', 'cnn', ')', 'gene', 'palmer', ',', 'the', 'second', 'prison', 'employee', 'charged', 'in', 'connection', 'with', 'the', 'escape', 'of', 'two', 'convicted', 'murderers', 'in', 'upstate', 'new', 'york', ',', 'admitted', 'he', 'provided', 'the', 'fugitives', 'with', 'tools', 'and', 'other', 'items', 'that', 'unintentionally', '\"', 'made', 'their', 'escape', 'easier', ',', '\"', 'according', 'to', 'a', 'statement', 'he', 'gave', 'the', 'state', 'police', '.', '\\n\\n', 'palmer', ',', 'a', 'prison', 'guard', 'for', 'more', 'than', '27', 'years', ',', 'told', 'investigators', 'that', 'within', 'the', 'last', 'eight', 'months', 'he', 'provided', 'inmate', 'david', 'sweat', 'with', 'a', 'pair', 'of', 'needle', '-', 'nose', 'pliers', 'and', 'a', 'flat', '-', 'head', 'screwdriver', ',', 'according', 'to', 'the', 'court', 'document', '.', 'late', 'last', 'month', ',', 'he', 'said', 'in', 'the', 'statement', ',', 'he', 'delivered', 'a', 'package', 'said', 'to', 'contain', 'a', 'pound', 'of', 'frozen', 'ground', 'beef', 'and', 'two', 'tubes', 'of', 'paint', 'to', 'the', 'other', 'inmate', ',', 'richard', 'matt', '\\n\\n', 'palmer', \"'s\", 'court', 'appearance', 'thursday', 'was', 'adjourned', 'because', 'he', 'is', 'changing', 'lawyers', '.', 'attorney', 'andrew', 'brockway', 'said', 'he', '\"', 'simply', 'does', \"n't\", 'have', 'the', 'resources', '\"', 'to', 'defend', 'palmer', ',', 'who', 'will', 'appear', 'in', 'court', 'on', 'monday', '.', '\\n\\n', 'joyce', 'mitchell', ',', 'another', 'prison', 'employee', 'charged', 'in', 'connection', 'with', 'the', 'escape', ',', 'admitted', 'to', 'putting', 'hacksaw', 'blades', 'and', 'drill', 'bits', 'into', 'the', 'hunk', 'of', 'hamburger', 'meat', ',', 'according', 'to', 'clinton', 'county', 'district', 'attorney', 'andrew', 'wylie', '.', 'she', 'has', 'pleaded', 'not', 'guilty', 'to', 'charges', 'of', 'aiding', 'the', 'escapees', '.', '\\n\\n', 'asked', 'whether', 'he', 'assisted', 'in', 'the', 'escape', ',', 'palmer', 'told', 'investigators', ':', '\"', 'no', '.', 'not', 'intentionally', '.', '\"', '\\n\\n', 'he', 'continued', ',', '\"', 'matt', 'provided', 'me', 'with', 'elaborate', 'paintings', 'and', 'information', 'on', 'the', 'illegal', 'acts', 'that', 'inmates', 'were', 'committing', 'within', 'the', 'facility', '.', 'in', 'turn', ',', 'i', 'provided', 'him', 'with', 'benefits', 'such', 'as', 'paint', ',', 'paintbrushes', ',', 'movement', 'of', 'inmates', ',', 'hamburger', 'meat', ',', 'altering', 'of', 'electrical', 'boxes', 'in', 'the', 'catwalk', 'areas', '.', '\\n\\n', '\"', 'i', 'did', 'not', 'realize', 'at', 'the', 'time', 'that', 'the', 'assistance', 'provided', 'to', 'matt', 'and', 'sweat', 'made', 'their', 'escape', 'easier', '.', 'the', 'altering', 'of', 'the', 'electrical', 'boxes', 'was', 'to', 'enhance', 'their', 'ability', 'to', 'cook', 'in', 'their', 'cells', '.', '\"', '\\n\\n', 'the', 'screwdriver', 'and', 'needle', '-', 'nose', 'pliers', 'weused', 'to', 'fix', 'electrical', 'breakers', 'in', 'the', 'catwalk', 'behind', 'their', 'cells', '.', 'that', 'area', 'was', 'part', 'of', 'the', 'escape', 'route', ',', 'an', 'official', 'familiar', 'with', 'the', 'investigation', 'told', 'cnn', 'on', 'wednesday', '.', '\\n\\n', 'palmer', \"'s\", 'statement', 'reveals', 'the', 'complicated', 'relationship', 'between', 'inmates', 'and', 'employees', 'at', 'the', 'prison', '.', '\\n\\n', 'on', 'another', 'occasion', ',', 'palmer', 'said', ',', 'he', 'helped', 'matt', 'conceal', '\"', 'two', '-', 'oil', 'based', 'tubes', '\"', 'of', 'paint', 'that', 'he', 'had', 'purchased', 'for', 'the', 'inmate', 'in', 'the', 'catwalk', '.', 'at', 'the', 'time', ',', 'sweat', 'was', 'under', 'investigation', 'and', 'palmer', 'said', 'he', 'had', 'matt', 'take', 'the', 'tubes', 'from', 'his', 'cell', 'to', 'the', 'catwalk', ',', 'where', 'the', 'paint', 'was', 'hidden', 'atop', 'an', 'air', 'vent', ',', 'according', 'to', 'the', 'court', 'document', '.', '\\n\\n', 'palmer', 'said', 'he', 'met', 'matt', 'in', '2009', 'and', 'sweat', 'about', 'five', 'years', 'ago', '.', 'he', 'said', 'he', 'bought', 'white', 'zinc', 'and', 'white', 'titanium', 'paint', 'and', 'paintbrushes', 'for', 'matt', 'on', 'two', 'occasions', ',', 'according', 'to', 'the', 'document', '.', 'palmer', 'also', 'said', 'he', 'bought', 'a', 'large', 'tube', 'of', 'acrylic', 'paint', 'for', 'sweat', 'about', 'two', 'years', 'ago', '.', 'he', 'said', 'he', 'gave', 'sweat', 'the', 'pliers', 'and', 'other', 'tools', 'on', 'four', 'occasions', '.', '\\n\\n', 'the', 'tools', 'were', 'found', 'at', 'palmer', \"'s\", 'home', 'after', 'police', 'executed', 'a', 'search', 'warrant', ',', 'according', 'to', 'the', 'official', 'familiar', 'with', 'the', 'investigation', '.', '\\n\\n', 'palmer', 'told', 'investigators', 'that', 'as', 'a', '\"', 'favor', '\"', 'he', 'allowed', 'sweat', 'to', '\"', 'change', 'the', 'electrical', 'wiring', 'in', 'the', 'cell', 'electrical', 'boxes', ',', '\"', 'the', 'document', 'said', '.', 'he', 'said', 'he', 'allowed', 'sweat', 'into', 'the', 'catwalk', 'of', 'the', 'block', 'where', 'the', 'prisoners', 'were', 'housed', '.', '\\n\\n', 'brockway', 'declined', 'to', 'comment', 'on', 'the', 'specific', 'charges', 'wednesday', '.', '\\n\\n', 'palmer', 'posted', 'bail', 'of', '$', '25,000', 'and', 'was', 'released', 'from', 'jail', 'early', 'thursday', '.', '\\n\\n', '\"', 'mr.', 'palmer', 'has', 'been', 'completely', 'cooperative', 'with', 'the', 'investigation', ',', '\"', 'brockway', 'said', '.', '\"', 'he', 'will', 'continue', 'to', 'cooperate', '.', 'he', \"'s\", 'a', 'man', 'of', 'integrity', 'who', 'made', 'some', 'mistakes', '.', '\"', '\\n\\n', 'according', 'to', 'the', 'court', 'document', ',', 'after', 'the', 'convicts', 'escaped', ',', 'palmer', 'tried', 'to', 'destroy', 'evidence', 'of', 'the', 'paintings', 'the', 'inmates', 'had', 'given', 'him', ',', 'burning', 'some', 'of', 'them', 'in', 'a', 'fire', 'pit', 'at', 'his', 'home', 'and', 'burying', 'others', 'in', 'nearby', 'woods', '.', '\\n\\n', 'he', 'faces', 'three', 'felony', 'charges', '--', 'one', 'count', 'of', 'promoting', 'prison', 'contraband', ',', 'two', 'counts', 'of', 'tampering', 'with', 'physical', 'evidence', '--', 'and', 'one', 'misdemeanor', 'charge', 'of', 'official', 'misconduct', '.', '\\n\\n', 'palmer', \"'s\", 'june', '20', 'interview', 'with', 'the', 'state', 'police', 'was', 'videotaped', ',', 'a', 'source', 'familiar', 'with', 'the', 'investigation', 'told', 'cnn', '.', '\\n\\n', 'access', 'to', 'the', 'catwalk', 'was', 'not', 'unusual', 'for', 'prisoners', '.', 'the', 'prison', 'used', 'inmates', 'to', 'do', 'plumbing', 'and', 'electric', 'work', ',', 'sometimes', 'allowing', 'them', 'to', 'go', 'in', 'the', 'catwalk', 'area', ',', 'a', 'former', 'maintenance', 'supervisor', 'said', '.', '\\n\\n', 'the', 'former', 'supervisor', ',', 'who', 'worked', 'at', 'the', 'prison', 'for', '35', 'years', ',', 'said', 'inmates', 'filled', 'those', 'positions', 'when', 'the', 'maintenance', 'department', 'was', 'short', 'staffed', '.', 'correction', 'officers', 'were', 'also', 'understaffed', 'at', 'times', ',', 'and', 'inmates', 'conducted', 'repair', 'work', 'unsupervised', '.', 'the', 'ex', '-', 'supervisor', 'left', 'the', 'facility', 'six', 'years', 'ago', '.', '\\n\\n', 'the', 'former', 'supervisor', 'said', 'inmates', 'worked', 'unplugging', 'toilets', ',', 'changing', 'lights', ',', 'fixing', 'leaks', 'and', 'repairing', 'wiring', '.', 'their', 'work', 'took', 'them', 'inside', 'cells', 'and', 'to', 'the', 'catwalks', 'behind', 'the', 'cell', 'walls', 'for', 'major', 'pipe', 'repairs', '.', '\\n\\n', 'inmates', 'sometimes', 'asked', 'prison', 'employees', 'for', 'favors', ',', 'such', 'as', 'sending', 'a', 'letter', 'or', 'asking', 'for', 'a', 'pack', 'of', 'cigarettes', ',', 'the', 'ex', '-', 'supervisor', 'said', '.', 'inmates', 'started', 'with', 'small', 'favors', 'and', 'followed', 'up', 'with', 'bigger', 'requests', ',', 'sometimes', 'threatening', 'to', 'turn', 'in', 'the', 'employee', 'for', 'delivering', 'on', 'the', 'smaller', 'offense', '.', '\\n\\n', 'palmer', 'said', 'life', 'as', 'a', 'prison', 'guard', 'was', 'as', 'miserable', 'as', 'those', 'of', 'the', 'prisoners', '.', '\"', 'with', 'the', 'money', 'that', 'they', 'pay', 'you', ',', 'you', \"'ll\", 'go', 'bald', ',', 'you', \"'ll\", 'have', 'high', 'blood', 'pressure', ',', 'you', \"'ll\", 'become', 'an', 'alcoholic', ',', 'you', \"'ll\", 'divorce', ',', 'and', 'then', 'you', \"'ll\", 'kill', 'yourself', ',', '\"', 'he', 'said', '.', '\\n\\n', 'mann', 'described', 'the', 'jail', 'scene', 'all', 'those', 'years', 'ago', ':', '\"', 'everywhere', 'we', 'go', ',', 'prisoners', 'are', 'handling', 'knives', 'and', 'power', 'tools', ',', '\"', 'he', 'said', 'in', '2000', '.', '\\n\\n', '\"', 'even', 'then', ',', 'that', 'detail', 'kind', 'of', 'freaked', 'me', 'out', ',', '\"', 'he', 'said', 'a', 'week', 'after', 'the', 'jail', 'break', '.', '\\n\\n', 'palmer', \"'s\", 'arrest', 'came', 'as', 'more', 'than', 'a', 'dozen', 'investigators', 'from', 'the', 'new', 'york', 'state', 'inspector', 'general', \"'s\", 'office', 'arrived', 'at', 'the', 'prison', 'to', 'investigate', 'possible', 'breaches', 'of', 'security', 'protocols', 'that', 'allowed', 'matt', 'and', 'sweat', 'to', 'escape', ',', 'a', 'state', 'law', 'enforcement', 'official', 'said', '.', 'the', 'two', 'men', 'have', 'been', 'on', 'the', 'lam', 'since', 'june', '6', '.', '\\n\\n', 'investigators', 'are', 'going', 'through', 'visitor', 'logs', 'and', 'documents', 'related', 'to', 'prisoner', 'and', 'employee', 'movements', 'at', 'the', 'jail', ',', 'the', 'official', 'said', '.', '\\n\\n', 'they', 'are', 'also', 'looking', 'into', 'whether', 'prison', 'guards', 'on', 'the', 'honor', 'block', 'would', 'sleep', 'during', 'their', 'evening', 'shifts', 'and', 'if', 'that', 'allowed', 'sweat', 'and', 'matt', 'to', 'remain', 'virtually', 'unsupervised', 'as', 'they', 'worked', 'to', 'prepare', 'their', 'escape', ',', 'a', 'law', 'enforcement', 'official', 'told', 'cnn', '.', '\\n\\n', 'as', 'authorities', 'try', 'to', 'figure', 'out', 'what', 'went', 'wrong', 'at', 'the', 'prison', ',', 'hundreds', 'of', 'law', 'enforcement', 'officers', 'are', 'still', 'rummaging', 'through', 'dense', 'woodland', 'surrounding', 'a', 'hunting', 'cabin', 'the', 'fugitives', 'are', 'believed', 'to', 'have', 'burglarized', '.', 'authorities', 'said', 'a', 'number', 'of', 'items', 'were', 'recovered', 'from', 'the', 'mountain', 'view', 'cabin', ',', 'some', '30', 'miles', 'west', 'of', 'the', 'jail', ',', 'including', 'a', 'sock', ',', 'according', 'to', 'wylie', '.', 'while', 'the', 'district', 'attorney', 'would', \"n't\", 'say', 'if', 'the', 'sock', \"'s\", 'red', 'markings', 'were', 'blood', ',', 'he', 'did', 'tell', 'cnn', \"'s\", 'anderson', 'cooper', ',', '\"', 'i', 'do', 'know', 'that', 'a', 'dna', 'profile', 'was', 'from', 'one', 'of', 'the', 'socks', '.', '\"', '\\n\\n', 'the', '75-square', '-', 'mile', 'primary', 'search', 'area', 'is', 'roughly', '20', 'miles', 'west', 'of', 'the', 'prison', '.', 'state', 'forest', 'rangers', 'describe', 'the', 'terrain', 'as', 'treacherous', ',', 'not', 'just', 'for', 'the', 'escapees', 'but', 'also', 'for', 'police', 'and', 'other', 'searchers', '.', '\\n\\n', '\"', 'the', 'area', 'is', 'heavily', 'forested', '.', 'the', 'undergrowth', 'is', 'thick', ',', '\"', 'capt', '.', 'john', 'strife', 'said', '.', '\"', 'the', 'vegetation', 'is', 'a', 'combination', 'of', 'trees', ',', 'saplings', 'and', 'brush', '.', '\"'], 'REAL'])\n"
     ]
    }
   ],
   "source": [
    "print(train_data[0].__dict__.keys())\n",
    "print(train_data[0].__dict__.values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_VOCAB_SIZE = 25000\n",
    "text.build_vocab(train_data, vectors = \"glove.6B.100d\", max_size=MAX_VOCAB_SIZE)\n",
    "title.build_vocab(train_data, vectors = \"glove.6B.100d\", max_size=MAX_VOCAB_SIZE)\n",
    "label.build_vocab(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 64\n",
    "\n",
    "# device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "device = 'cpu'\n",
    "\n",
    "train_iterator, validation_iterator, test_iterator = BucketIterator.splits(\n",
    "    (train_data, validation_data, test_data),\n",
    "    batch_size=BATCH_SIZE,\n",
    "    sort=False,\n",
    "    device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "class RNN(nn.Module):\n",
    "    def __init__(self, input_dim, embedding_dim, hidden_dim, output_dim):\n",
    "        super().__init__()\n",
    "        self.embedding = nn.Embedding(input_dim, embedding_dim)\n",
    "        self.rnn = nn.RNN(embedding_dim, hidden_dim)\n",
    "        self.fc = nn.Linear(hidden_dim, output_dim)\n",
    "    \n",
    "    def forward(self, text):\n",
    "        embedded = self.embedding(text)\n",
    "\n",
    "        output, hidden = self.rnn(embedded)\n",
    "\n",
    "        assert torch.equal(output[-1,:,:], hidden.squeeze(0))\n",
    "\n",
    "        return self.fc(hidden.squeeze(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "INPUT_DIM = len(text.vocab)\n",
    "EMBEDDING_DIM = 100\n",
    "HIDDEN_DIM = 256\n",
    "OUTPUT_DIM = 1\n",
    "\n",
    "model = RNN(INPUT_DIM, EMBEDDING_DIM, HIDDEN_DIM, OUTPUT_DIM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "This model has 2,592,105 trainable parameters\n"
     ]
    }
   ],
   "source": [
    "def count_parameters(model):\n",
    "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "print(f'This model has {count_parameters(model):,} trainable parameters')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "\n",
    "optimizer = optim.SGD(model.parameters(), lr=1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.BCEWithLogitsLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = model.to(device)\n",
    "criterion = criterion.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def binary_accuracy(preds, y):\n",
    "    rounded_preds = torch.round(torch.sigmoid(preds))\n",
    "    correct = (rounded_preds == y).float()\n",
    "    acc = correct.sum()/len(correct)\n",
    "    return acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, iterator, optimizer, criterion):\n",
    "    epoch_loss = 0\n",
    "    epoch_acc = 0\n",
    "\n",
    "    model.train()\n",
    "\n",
    "    for batch in iterator:\n",
    "        optimizer.zero_grad()\n",
    "        predictions = model.forward(batch.text).squeeze(1)\n",
    "        loss = criterion(predictions, batch.label)\n",
    "\n",
    "        acc = binary_accuracy(predictions, batch.label)\n",
    "\n",
    "        loss.backward()     # calcualte the gradient of each param\n",
    "        optimizer.step()\n",
    "\n",
    "        epoch_loss += loss.item()\n",
    "        epoch_acc += acc.item()\n",
    "    return epoch_loss/len(iterator), epoch_acc/len(iterator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model, iterator, criterion):\n",
    "    epoch_loss = 0\n",
    "    epoch_acc = 0\n",
    "\n",
    "    model.eval()\n",
    "\n",
    "    with torch.no_grad():   # don't calcualte gradients in this block\n",
    "        for batch in iterator:\n",
    "            predictions = model.forward(batch.text).squeeze(1)\n",
    "            loss = criterion(predictions, batch.label)\n",
    "\n",
    "            acc = binary_accuracy(predictions, batch.label)\n",
    "\n",
    "            epoch_loss += loss.item()\n",
    "            epoch_acc += acc.item()\n",
    "\n",
    "    return epoch_loss/len(iterator), epoch_acc/len(iterator)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "def epoch_time(start_time, end_time):\n",
    "    elapsed_time = end_time - start_time\n",
    "    elapsed_mins = int(elapsed_time/60)\n",
    "    elapsed_secs = int(elapsed_time - (elapsed_mins * 60))\n",
    "    return elapsed_mins, elapsed_secs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "N_EPOCHS = 6\n",
    "best_validation_loss = float('inf')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch: 01 | Epoch Time: 7m 17s\n",
      "\tTrain Loss: 0.693 | Train Acc: 49.03%\n",
      "\tValidation Loss: 0.693 | Validation Acc: 47.12%\n",
      "Epoch: 02 | Epoch Time: 7m 43s\n",
      "\tTrain Loss: 0.693 | Train Acc: 49.54%\n",
      "\tValidation Loss: 0.693 | Validation Acc: 52.86%\n",
      "Epoch: 03 | Epoch Time: 7m 33s\n",
      "\tTrain Loss: 0.693 | Train Acc: 49.76%\n",
      "\tValidation Loss: 0.693 | Validation Acc: 47.12%\n",
      "Epoch: 04 | Epoch Time: 7m 48s\n",
      "\tTrain Loss: 0.693 | Train Acc: 49.69%\n",
      "\tValidation Loss: 0.692 | Validation Acc: 52.86%\n",
      "Epoch: 05 | Epoch Time: 7m 35s\n",
      "\tTrain Loss: 0.693 | Train Acc: 49.35%\n",
      "\tValidation Loss: 0.693 | Validation Acc: 47.12%\n",
      "Epoch: 06 | Epoch Time: 7m 53s\n",
      "\tTrain Loss: 0.693 | Train Acc: 49.78%\n",
      "\tValidation Loss: 0.693 | Validation Acc: 47.12%\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(N_EPOCHS):\n",
    "    start_time = time.time()\n",
    "\n",
    "    train_loss, train_acc = train(model, train_iterator, optimizer, criterion)\n",
    "    validation_loss, validation_acc = evaluate(model, validation_iterator, criterion)\n",
    "\n",
    "    end_time = time.time()\n",
    "\n",
    "    epoch_mins, epoch_secs = epoch_time(start_time, end_time)\n",
    "\n",
    "    if validation_loss < best_validation_loss:\n",
    "        best_valid_loss = validation_loss\n",
    "        torch.save(model.state_dict(), 'RNN-Model.pt')\n",
    "    print(f'Epoch: {epoch+1:02} | Epoch Time: {epoch_mins}m {epoch_secs}s')\n",
    "    print(f'\\tTrain Loss: {train_loss:.3f} | Train Acc: {train_acc*100:.2f}%')\n",
    "    print(f'\\tValidation Loss: {validation_loss:.3f} | Validation Acc: {validation_acc*100:.2f}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Test Loss: 0.693 | Test Acc: 52.15%\n"
     ]
    }
   ],
   "source": [
    "model.load_state_dict(torch.load('RNN-Model.pt'))\n",
    "test_loss, test_acc = evaluate(model, test_iterator, criterion)\n",
    "print(f'Test Loss: {test_loss:.3f} | Test Acc: {test_acc*100:.2f}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}