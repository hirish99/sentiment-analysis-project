{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.6"
    },
    "colab": {
      "name": "Copy of torchText2.ipynb",
      "provenance": []
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_8nq4LeWLqYs",
        "outputId": "68668ebd-f9d2-4373-d36b-640318f74af0"
      },
      "source": [
        "!pip install torchtext==0.4.0"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: torchtext==0.4.0 in /usr/local/lib/python3.7/dist-packages (0.4.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from torchtext==0.4.0) (2.23.0)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.7/dist-packages (from torchtext==0.4.0) (1.7.1+cu101)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from torchtext==0.4.0) (1.15.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from torchtext==0.4.0) (1.19.5)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from torchtext==0.4.0) (4.41.1)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->torchtext==0.4.0) (2020.12.5)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->torchtext==0.4.0) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->torchtext==0.4.0) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->torchtext==0.4.0) (3.0.4)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch->torchtext==0.4.0) (3.7.4.3)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sD3HsZG0OH4K",
        "outputId": "46d08ac9-08e2-4c49-9b16-8081024f56b1"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MCh7v397CVnA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "67c7eaac-9f6a-4a66-e80a-ebd6ae8ddd28"
      },
      "source": [
        "# New Stuff\n",
        "from torchtext.data import Field, TabularDataset, BucketIterator, LabelField\n",
        "import spacy\n",
        "import torch\n",
        "\n",
        "torch.backends.cudnn.deterministic = True\n",
        "print(torch.cuda.device_count())\n",
        "\n",
        "# spacy_en = spacy.load('en')\n",
        "\n",
        "#     return [token.text for token in spacy_en.tokenizer(text)]\n",
        "\n",
        "\n",
        "#By default sequential = True, use_vocab = True, no need to include these parameters. See here for explanation of\n",
        "#these parameters: https://torchtext.readthedocs.io/en/latest/data.html#fields\n",
        "title = Field(tokenize='spacy', lower=True)\n",
        "text = Field(tokenize='spacy', tokenizer_language='en_core_web_sm', include_lengths = True, lower=True)\n",
        "label = LabelField(dtype=torch.float)\n",
        "\n",
        "fields = {'text': ('text', text), 'label': ('label', label), 'title': ('title', title)}"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m8NQtcb3HlWu",
        "outputId": "8447bf90-ea97-4ad6-8e60-7f1fac821bb4"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "94nrn7V1II_D",
        "outputId": "b3a58294-5bb7-4e86-c46f-6984ca5c0d91"
      },
      "source": [
        "ls"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[0m\u001b[01;34mdrive\u001b[0m/  LSTM-Model.pt  news.csv  news_short.csv  \u001b[01;34msample_data\u001b[0m/\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r2phAY7wCVnK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c4011d8b-2b8f-48fc-b12e-310e70aa352a"
      },
      "source": [
        "train_data = TabularDataset.splits(\n",
        "    path='',\n",
        "    train='news.csv',\n",
        "    # validation='news.csv',\n",
        "    # test='news.csv',\n",
        "    format='csv',\n",
        "    fields=fields)[0]\n",
        "\n",
        "print(type(train_data))\n",
        "\n",
        "print(\"Num of training: \", len(train_data))\n",
        "# print(\"Num of validation: \", len(validation_data))\n",
        "# print(\"Num of testing: \", len(test_data))"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'torchtext.data.dataset.TabularDataset'>\n",
            "Num of training:  6335\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ITc7vs-EH3CG",
        "outputId": "d96cef67-22f1-48cf-ddf7-96eb02592cc8"
      },
      "source": [
        "%ls"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[0m\u001b[01;34mdrive\u001b[0m/  LSTM-Model.pt  news.csv  news_short.csv  \u001b[01;34msample_data\u001b[0m/\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5dOj2e8GCVnL",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "36d02dfe-2798-41f9-9436-5bf082a61c97"
      },
      "source": [
        "train_data, validation_data = train_data.split(split_ratio=0.65)\n",
        "validation_data, test_data = validation_data.split(split_ratio=0.5)\n",
        "print(\"Num of training: \", len(train_data))\n",
        "print(\"Num of validation: \", len(validation_data))\n",
        "print(\"Num of testing: \", len(test_data))"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Num of training:  4118\n",
            "Num of validation:  1108\n",
            "Num of testing:  1109\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2fXqTPgjCVnM",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3376643c-d187-449f-ebbe-4565158ffb15"
      },
      "source": [
        "vars(train_data[0])\n",
        "# print(train_data[0])"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'label': 'REAL',\n",
              " 'text': ['to',\n",
              "  'understand',\n",
              "  'what',\n",
              "  'ails',\n",
              "  'hillary',\n",
              "  'clinton',\n",
              "  ',',\n",
              "  'let',\n",
              "  '’s',\n",
              "  'rewind',\n",
              "  'past',\n",
              "  'iowa',\n",
              "  'and',\n",
              "  'new',\n",
              "  'hampshire',\n",
              "  '–',\n",
              "  'two',\n",
              "  'years',\n",
              "  'back',\n",
              "  ',',\n",
              "  'in',\n",
              "  'fact',\n",
              "  ',',\n",
              "  'to',\n",
              "  'a',\n",
              "  'speech',\n",
              "  'in',\n",
              "  'new',\n",
              "  'orleans',\n",
              "  'before',\n",
              "  'the',\n",
              "  'national',\n",
              "  'auto',\n",
              "  'dealers',\n",
              "  'association',\n",
              "  'and',\n",
              "  'these',\n",
              "  'words',\n",
              "  ':',\n",
              "  '\\n\\n',\n",
              "  '“',\n",
              "  'the',\n",
              "  'last',\n",
              "  'time',\n",
              "  'i',\n",
              "  'actually',\n",
              "  'drove',\n",
              "  'a',\n",
              "  'car',\n",
              "  'myself',\n",
              "  'was',\n",
              "  '1996',\n",
              "  '.',\n",
              "  'i',\n",
              "  'remember',\n",
              "  'it',\n",
              "  'very',\n",
              "  'well',\n",
              "  '.',\n",
              "  'unfortunately',\n",
              "  ',',\n",
              "  'so',\n",
              "  'does',\n",
              "  'the',\n",
              "  'secret',\n",
              "  'service',\n",
              "  ',',\n",
              "  'which',\n",
              "  'is',\n",
              "  'why',\n",
              "  'i',\n",
              "  'have',\n",
              "  \"n't\",\n",
              "  'driven',\n",
              "  'since',\n",
              "  'then',\n",
              "  '.',\n",
              "  '”',\n",
              "  '\\n\\n',\n",
              "  'that',\n",
              "  'one',\n",
              "  'passage',\n",
              "  'underscores',\n",
              "  'three',\n",
              "  'of',\n",
              "  'clinton',\n",
              "  '’s',\n",
              "  'present',\n",
              "  '-',\n",
              "  'day',\n",
              "  'woes',\n",
              "  ':',\n",
              "  'she',\n",
              "  '’s',\n",
              "  'lived',\n",
              "  'in',\n",
              "  'a',\n",
              "  'cocoon',\n",
              "  'for',\n",
              "  'well',\n",
              "  'over',\n",
              "  'two',\n",
              "  'decades',\n",
              "  ';',\n",
              "  'she',\n",
              "  '’s',\n",
              "  'not',\n",
              "  'all',\n",
              "  'that',\n",
              "  'entertaining',\n",
              "  ';',\n",
              "  'there',\n",
              "  'may',\n",
              "  'be',\n",
              "  'no',\n",
              "  'limit',\n",
              "  'to',\n",
              "  'what',\n",
              "  'she',\n",
              "  'and',\n",
              "  'her',\n",
              "  'husband',\n",
              "  'will',\n",
              "  'do',\n",
              "  'for',\n",
              "  'a',\n",
              "  'quick',\n",
              "  'buck',\n",
              "  '(',\n",
              "  'that',\n",
              "  'one',\n",
              "  'appearance',\n",
              "  'earned',\n",
              "  'hillary',\n",
              "  'a',\n",
              "  '$',\n",
              "  '325,000',\n",
              "  'honorarium',\n",
              "  ')',\n",
              "  '.',\n",
              "  '\\n\\n',\n",
              "  'speaking',\n",
              "  'of',\n",
              "  'clinton',\n",
              "  '’s',\n",
              "  'motoring',\n",
              "  'skills',\n",
              "  ',',\n",
              "  'there',\n",
              "  '’s',\n",
              "  'a',\n",
              "  'fourth',\n",
              "  'problem',\n",
              "  ':',\n",
              "  'rather',\n",
              "  'than',\n",
              "  'turn',\n",
              "  'into',\n",
              "  'the',\n",
              "  'skid',\n",
              "  'caused',\n",
              "  'by',\n",
              "  'alarming',\n",
              "  'droves',\n",
              "  'of',\n",
              "  'young',\n",
              "  'and',\n",
              "  'women',\n",
              "  'voters',\n",
              "  'jilting',\n",
              "  'her',\n",
              "  'for',\n",
              "  'vermont',\n",
              "  'sen.',\n",
              "  'bernie',\n",
              "  'sanders',\n",
              "  ',',\n",
              "  'she',\n",
              "  '’s',\n",
              "  'overcorrected',\n",
              "  '–',\n",
              "  'trying',\n",
              "  'too',\n",
              "  'hard',\n",
              "  'to',\n",
              "  'pawn',\n",
              "  'herself',\n",
              "  'off',\n",
              "  'as',\n",
              "  'a',\n",
              "  'feverish',\n",
              "  'progressive',\n",
              "  ';',\n",
              "  'leaning',\n",
              "  'too',\n",
              "  'hard',\n",
              "  'on',\n",
              "  '“',\n",
              "  'lean',\n",
              "  'in',\n",
              "  '”',\n",
              "  'adherents',\n",
              "  'to',\n",
              "  'stay',\n",
              "  'true',\n",
              "  'to',\n",
              "  'the',\n",
              "  'sisterhood',\n",
              "  '.',\n",
              "  '\\n\\n',\n",
              "  'it',\n",
              "  '’s',\n",
              "  'one',\n",
              "  'way',\n",
              "  'to',\n",
              "  'parse',\n",
              "  'thursday',\n",
              "  '’s',\n",
              "  'democratic',\n",
              "  'debate',\n",
              "  'in',\n",
              "  'milwaukee',\n",
              "  ':',\n",
              "  'would',\n",
              "  'clinton',\n",
              "  'continue',\n",
              "  'her',\n",
              "  'february',\n",
              "  'fishtailing',\n",
              "  ',',\n",
              "  'or',\n",
              "  'find',\n",
              "  'a',\n",
              "  'smarter',\n",
              "  'way',\n",
              "  'to',\n",
              "  'pull',\n",
              "  'out',\n",
              "  'of',\n",
              "  'the',\n",
              "  'skid',\n",
              "  '?',\n",
              "  '\\n\\n',\n",
              "  'here',\n",
              "  'are',\n",
              "  'three',\n",
              "  'observations',\n",
              "  '.',\n",
              "  '\\n\\n',\n",
              "  '1',\n",
              "  '.',\n",
              "  'did',\n",
              "  'hillary',\n",
              "  'alter',\n",
              "  'her',\n",
              "  'message',\n",
              "  '?',\n",
              "  'yes',\n",
              "  '–',\n",
              "  'and',\n",
              "  'it',\n",
              "  'began',\n",
              "  'with',\n",
              "  'her',\n",
              "  'opening',\n",
              "  'statement',\n",
              "  '.',\n",
              "  '\\n\\n',\n",
              "  'clinton',\n",
              "  'noted',\n",
              "  'voters',\n",
              "  '’',\n",
              "  'anger',\n",
              "  'toward',\n",
              "  'the',\n",
              "  'economy',\n",
              "  '(',\n",
              "  'is',\n",
              "  'n’t',\n",
              "  'it',\n",
              "  'more',\n",
              "  'like',\n",
              "  'frustration',\n",
              "  '?',\n",
              "  ')',\n",
              "  ',',\n",
              "  'singling',\n",
              "  'out',\n",
              "  '“',\n",
              "  'young',\n",
              "  'people',\n",
              "  '”',\n",
              "  'as',\n",
              "  'those',\n",
              "  'most',\n",
              "  'furious',\n",
              "  ',',\n",
              "  'and',\n",
              "  'sounded',\n",
              "  'bernie',\n",
              "  '-',\n",
              "  'lite',\n",
              "  'in',\n",
              "  'calling',\n",
              "  'for',\n",
              "  '“',\n",
              "  'unaccountable',\n",
              "  'money',\n",
              "  '”',\n",
              "  'to',\n",
              "  'be',\n",
              "  'taken',\n",
              "  'out',\n",
              "  'of',\n",
              "  'the',\n",
              "  'system',\n",
              "  'and',\n",
              "  'claiming',\n",
              "  'that',\n",
              "  'america',\n",
              "  '’s',\n",
              "  'economy',\n",
              "  'is',\n",
              "  'rigged',\n",
              "  '“',\n",
              "  'for',\n",
              "  'those',\n",
              "  'at',\n",
              "  'the',\n",
              "  'top',\n",
              "  '”',\n",
              "  '(',\n",
              "  'but',\n",
              "  'certainly',\n",
              "  'not',\n",
              "  'those',\n",
              "  'industrious',\n",
              "  'souls',\n",
              "  'giving',\n",
              "  'six',\n",
              "  '-',\n",
              "  'figure',\n",
              "  'speeches',\n",
              "  ')',\n",
              "  '.',\n",
              "  '\\n\\n',\n",
              "  'credit',\n",
              "  'clinton',\n",
              "  'with',\n",
              "  'waking',\n",
              "  'up',\n",
              "  'to',\n",
              "  '2016',\n",
              "  'reality',\n",
              "  '.',\n",
              "  'which',\n",
              "  'did',\n",
              "  'n’t',\n",
              "  'come',\n",
              "  'easy',\n",
              "  '–',\n",
              "  'not',\n",
              "  'until',\n",
              "  'new',\n",
              "  'hampshire',\n",
              "  '’s',\n",
              "  'gobsmacking',\n",
              "  '.',\n",
              "  '\\n\\n',\n",
              "  'in',\n",
              "  '1992',\n",
              "  ',',\n",
              "  'bill',\n",
              "  'clinton',\n",
              "  'had',\n",
              "  'the',\n",
              "  'luxury',\n",
              "  'of',\n",
              "  'running',\n",
              "  'in',\n",
              "  'a',\n",
              "  'pre',\n",
              "  '-',\n",
              "  'digital',\n",
              "  'time',\n",
              "  'when',\n",
              "  'the',\n",
              "  'democratic',\n",
              "  'hard',\n",
              "  'left',\n",
              "  ',',\n",
              "  'beaten',\n",
              "  'down',\n",
              "  'after',\n",
              "  'three',\n",
              "  'presidential',\n",
              "  'meltdowns',\n",
              "  ',',\n",
              "  'offered',\n",
              "  'little',\n",
              "  'in',\n",
              "  'the',\n",
              "  'way',\n",
              "  'of',\n",
              "  'resistance',\n",
              "  '.',\n",
              "  'in',\n",
              "  '2008',\n",
              "  ',',\n",
              "  'having',\n",
              "  'voted',\n",
              "  'for',\n",
              "  'the',\n",
              "  'iraq',\n",
              "  'war',\n",
              "  ',',\n",
              "  'hillary',\n",
              "  'was',\n",
              "  'too',\n",
              "  'late',\n",
              "  'to',\n",
              "  'wake',\n",
              "  'up',\n",
              "  'to',\n",
              "  'liberal',\n",
              "  'sturm',\n",
              "  'und',\n",
              "  'drang',\n",
              "  '.',\n",
              "  '\\n\\n',\n",
              "  'in',\n",
              "  '2016',\n",
              "  ',',\n",
              "  'clinton',\n",
              "  'understands',\n",
              "  'the',\n",
              "  'kooky',\n",
              "  'old',\n",
              "  'guy',\n",
              "  'to',\n",
              "  'the',\n",
              "  'right',\n",
              "  'of',\n",
              "  'her',\n",
              "  'on',\n",
              "  'the',\n",
              "  'university',\n",
              "  'of',\n",
              "  'wisconsin',\n",
              "  '-',\n",
              "  'milwaukee',\n",
              "  'stage',\n",
              "  '(',\n",
              "  'physically',\n",
              "  ',',\n",
              "  'not',\n",
              "  'philosophically',\n",
              "  ')',\n",
              "  'is',\n",
              "  'on',\n",
              "  'to',\n",
              "  'something',\n",
              "  '–',\n",
              "  'and',\n",
              "  'she',\n",
              "  'wants',\n",
              "  'in',\n",
              "  'on',\n",
              "  'his',\n",
              "  'act',\n",
              "  '.',\n",
              "  '\\n\\n',\n",
              "  'and',\n",
              "  'so',\n",
              "  'it',\n",
              "  '’s',\n",
              "  'official',\n",
              "  ':',\n",
              "  'hillary',\n",
              "  'feels',\n",
              "  'the',\n",
              "  'bern',\n",
              "  '.',\n",
              "  '.',\n",
              "  '.',\n",
              "  'until',\n",
              "  'bernie',\n",
              "  '’s',\n",
              "  'out',\n",
              "  'of',\n",
              "  'the',\n",
              "  'race',\n",
              "  '.',\n",
              "  '\\n\\n',\n",
              "  '2',\n",
              "  '.',\n",
              "  '\\xa0 ',\n",
              "  'is',\n",
              "  'bernie',\n",
              "  'serious',\n",
              "  'about',\n",
              "  'winning',\n",
              "  'this',\n",
              "  '?',\n",
              "  'we',\n",
              "  'can',\n",
              "  'quibble',\n",
              "  'over',\n",
              "  'the',\n",
              "  'small',\n",
              "  'stuff',\n",
              "  '–',\n",
              "  'like',\n",
              "  'the',\n",
              "  'batch',\n",
              "  'of',\n",
              "  'spending',\n",
              "  'ideas',\n",
              "  'doubling',\n",
              "  'the',\n",
              "  'national',\n",
              "  'debt',\n",
              "  '.',\n",
              "  'or',\n",
              "  'how',\n",
              "  'he',\n",
              "  '’d',\n",
              "  'win',\n",
              "  'a',\n",
              "  'single',\n",
              "  'vote',\n",
              "  'in',\n",
              "  'congress',\n",
              "  '.',\n",
              "  '\\n\\n',\n",
              "  'not',\n",
              "  'unlike',\n",
              "  'donald',\n",
              "  'trump',\n",
              "  ',',\n",
              "  'sanders',\n",
              "  'is',\n",
              "  'an',\n",
              "  'implausibly',\n",
              "  'electable',\n",
              "  'candidate',\n",
              "  'who',\n",
              "  '’s',\n",
              "  'cornered',\n",
              "  'the',\n",
              "  'market',\n",
              "  'on',\n",
              "  '“',\n",
              "  'you',\n",
              "  '’re',\n",
              "  'being',\n",
              "  'ripped',\n",
              "  'off',\n",
              "  '”',\n",
              "  'simplicity',\n",
              "  ':',\n",
              "  '“',\n",
              "  'the',\n",
              "  'american',\n",
              "  'people',\n",
              "  'are',\n",
              "  'tired',\n",
              "  'of',\n",
              "  'establishment',\n",
              "  'politics',\n",
              "  ',',\n",
              "  'tired',\n",
              "  'of',\n",
              "  'establishment',\n",
              "  'economics',\n",
              "  '.',\n",
              "  '.',\n",
              "  '.',\n",
              "  '”',\n",
              "  '\\n\\n',\n",
              "  'the',\n",
              "  'problem',\n",
              "  ':',\n",
              "  'preaching',\n",
              "  'the',\n",
              "  '(',\n",
              "  'democratic',\n",
              "  ')',\n",
              "  'socialist',\n",
              "  'gospel',\n",
              "  'is',\n",
              "  'n’t',\n",
              "  'a',\n",
              "  'blueprint',\n",
              "  'for',\n",
              "  'victory',\n",
              "  'beyond',\n",
              "  'the',\n",
              "  'most',\n",
              "  'lilywhite',\n",
              "  'of',\n",
              "  'democratic',\n",
              "  'electorates',\n",
              "  '.',\n",
              "  'sanders',\n",
              "  'needs',\n",
              "  'to',\n",
              "  'call',\n",
              "  'out',\n",
              "  'clinton',\n",
              "  'in',\n",
              "  'more',\n",
              "  'glaring',\n",
              "  'terms',\n",
              "  '.',\n",
              "  'otherwise',\n",
              "  ',',\n",
              "  'he',\n",
              "  '’s',\n",
              "  'gum',\n",
              "  'on',\n",
              "  'her',\n",
              "  'shoe',\n",
              "  '–',\n",
              "  'a',\n",
              "  'protest',\n",
              "  'vote',\n",
              "  'that',\n",
              "  'wo',\n",
              "  'n’t',\n",
              "  'win',\n",
              "  'many',\n",
              "  'states',\n",
              "  'and',\n",
              "  ',',\n",
              "  'as',\n",
              "  'we',\n",
              "  '’ve',\n",
              "  'already',\n",
              "  'seen',\n",
              "  'post',\n",
              "  '-',\n",
              "  'new',\n",
              "  'hampshire',\n",
              "  ',',\n",
              "  'will',\n",
              "  'get',\n",
              "  'rolled',\n",
              "  'in',\n",
              "  'the',\n",
              "  'contest',\n",
              "  'that',\n",
              "  'counts',\n",
              "  'most',\n",
              "  ':',\n",
              "  'the',\n",
              "  'delegate',\n",
              "  'count',\n",
              "  '.',\n",
              "  '\\n\\n',\n",
              "  'take',\n",
              "  'the',\n",
              "  'issue',\n",
              "  'of',\n",
              "  'illegal',\n",
              "  'immigration',\n",
              "  'as',\n",
              "  'an',\n",
              "  'example',\n",
              "  'of',\n",
              "  'how',\n",
              "  'sanders',\n",
              "  'falls',\n",
              "  'short',\n",
              "  '.',\n",
              "  'in',\n",
              "  'trying',\n",
              "  'to',\n",
              "  'clarify',\n",
              "  'his',\n",
              "  '2007',\n",
              "  'senate',\n",
              "  'vote',\n",
              "  'against',\n",
              "  'a',\n",
              "  'senate',\n",
              "  'reform',\n",
              "  'plan',\n",
              "  ',',\n",
              "  'he',\n",
              "  'opted',\n",
              "  'to',\n",
              "  'get',\n",
              "  'all',\n",
              "  'prickly',\n",
              "  'about',\n",
              "  'children',\n",
              "  '’s',\n",
              "  'lives',\n",
              "  'rather',\n",
              "  'than',\n",
              "  'prick',\n",
              "  'holes',\n",
              "  'in',\n",
              "  'clinton',\n",
              "  '’s',\n",
              "  'record',\n",
              "  '–',\n",
              "  'beginning',\n",
              "  'with',\n",
              "  'not',\n",
              "  'being',\n",
              "  'consistent',\n",
              "  'on',\n",
              "  'immigration',\n",
              "  '.',\n",
              "  '\\n\\n',\n",
              "  'it',\n",
              "  'was',\n",
              "  'n’t',\n",
              "  'the',\n",
              "  'only',\n",
              "  'opening',\n",
              "  'he',\n",
              "  'missed',\n",
              "  '.',\n",
              "  '\\n\\n',\n",
              "  'sanders',\n",
              "  'could',\n",
              "  'have',\n",
              "  'asked',\n",
              "  'how',\n",
              "  'clinton',\n",
              "  'could',\n",
              "  'credibly',\n",
              "  'bemoan',\n",
              "  'the',\n",
              "  'state',\n",
              "  'of',\n",
              "  'black',\n",
              "  'america',\n",
              "  ',',\n",
              "  'having',\n",
              "  'watched',\n",
              "  'her',\n",
              "  'husband',\n",
              "  'sign',\n",
              "  'welfare',\n",
              "  'reform',\n",
              "  'and',\n",
              "  'federal',\n",
              "  'sentencing',\n",
              "  'laws',\n",
              "  ',',\n",
              "  'or',\n",
              "  'why',\n",
              "  'she',\n",
              "  'now',\n",
              "  'espouses',\n",
              "  'gay',\n",
              "  'rights',\n",
              "  'having',\n",
              "  'opposed',\n",
              "  'same',\n",
              "  '-',\n",
              "  'sex',\n",
              "  'marriage',\n",
              "  'in',\n",
              "  '2008',\n",
              "  '.',\n",
              "  '\\n\\n',\n",
              "  'sanders',\n",
              "  '’',\n",
              "  'trump',\n",
              "  'card',\n",
              "  '–',\n",
              "  'and',\n",
              "  'hillary',\n",
              "  '’s',\n",
              "  'achilles',\n",
              "  'heel',\n",
              "  '–',\n",
              "  'is',\n",
              "  'authenticity',\n",
              "  ';',\n",
              "  'he',\n",
              "  'believes',\n",
              "  'what',\n",
              "  'he',\n",
              "  'says',\n",
              "  ';',\n",
              "  'she',\n",
              "  'says',\n",
              "  'what',\n",
              "  'she',\n",
              "  'believes',\n",
              "  'will',\n",
              "  'win',\n",
              "  'the',\n",
              "  'moment',\n",
              "  '.',\n",
              "  '\\n\\n',\n",
              "  'if',\n",
              "  'sanders',\n",
              "  'wants',\n",
              "  'to',\n",
              "  'prevail',\n",
              "  'beyond',\n",
              "  'a',\n",
              "  'random',\n",
              "  'few',\n",
              "  'states',\n",
              "  ',',\n",
              "  'he',\n",
              "  'has',\n",
              "  'to',\n",
              "  'drive',\n",
              "  'home',\n",
              "  'that',\n",
              "  'argument',\n",
              "  '.',\n",
              "  'waiting',\n",
              "  'until',\n",
              "  'the',\n",
              "  'debate',\n",
              "  '’s',\n",
              "  'closing',\n",
              "  'minutes',\n",
              "  'to',\n",
              "  'remind',\n",
              "  'democrats',\n",
              "  'that',\n",
              "  'she',\n",
              "  'ran',\n",
              "  'against',\n",
              "  'obama',\n",
              "  ',',\n",
              "  'not',\n",
              "  'him',\n",
              "  ',',\n",
              "  'does',\n",
              "  'n’t',\n",
              "  'cut',\n",
              "  'it',\n",
              "  '.',\n",
              "  '\\n\\n',\n",
              "  '3',\n",
              "  '.',\n",
              "  '\\xa0\\xa0 ',\n",
              "  'on',\n",
              "  ',',\n",
              "  'wisconsin',\n",
              "  '.',\n",
              "  '.',\n",
              "  '.',\n",
              "  'to',\n",
              "  'nevada',\n",
              "  'and',\n",
              "  'south',\n",
              "  'carolina',\n",
              "  '.',\n",
              "  'the',\n",
              "  'drinking',\n",
              "  'game',\n",
              "  'only',\n",
              "  'a',\n",
              "  'fool',\n",
              "  'would',\n",
              "  'have',\n",
              "  'accepted',\n",
              "  ':',\n",
              "  'imbibing',\n",
              "  'whenever',\n",
              "  'clinton',\n",
              "  'tossed',\n",
              "  'a',\n",
              "  'line',\n",
              "  'to',\n",
              "  'those',\n",
              "  'voters',\n",
              "  'she',\n",
              "  'most',\n",
              "  'immediately',\n",
              "  'needs',\n",
              "  '(',\n",
              "  'well',\n",
              "  ',',\n",
              "  'that',\n",
              "  'and',\n",
              "  'bernie',\n",
              "  'saying',\n",
              "  '“',\n",
              "  'billionaires',\n",
              "  '”',\n",
              "  'or',\n",
              "  '“',\n",
              "  'wall',\n",
              "  'street',\n",
              "  '”',\n",
              "  ')',\n",
              "  '.',\n",
              "  '\\n\\n',\n",
              "  'for',\n",
              "  'a',\n",
              "  'nevada',\n",
              "  'that',\n",
              "  '’s',\n",
              "  'almost',\n",
              "  '28',\n",
              "  'percent',\n",
              "  'latino',\n",
              "  '(',\n",
              "  '50',\n",
              "  'percent',\n",
              "  'above',\n",
              "  'the',\n",
              "  'national',\n",
              "  'average',\n",
              "  ')',\n",
              "  'and',\n",
              "  'votes',\n",
              "  'on',\n",
              "  'the',\n",
              "  'democratic',\n",
              "  'side',\n",
              "  'a',\n",
              "  'week',\n",
              "  'from',\n",
              "  'saturday',\n",
              "  ':',\n",
              "  '“',\n",
              "  '[',\n",
              "  'h]ard',\n",
              "  '-',\n",
              "  'working',\n",
              "  'immigrant',\n",
              "  'families',\n",
              "  ',',\n",
              "  'living',\n",
              "  'in',\n",
              "  'fear',\n",
              "  ',',\n",
              "  'who',\n",
              "  'should',\n",
              "  'be',\n",
              "  'brought',\n",
              "  'out',\n",
              "  'of',\n",
              "  'the',\n",
              "  'shadows',\n",
              "  'so',\n",
              "  'they',\n",
              "  'and',\n",
              "  'their',\n",
              "  'children',\n",
              "  'can',\n",
              "  'have',\n",
              "  'a',\n",
              "  'better',\n",
              "  'future',\n",
              "  '”',\n",
              "  '.',\n",
              "  '\\n\\n',\n",
              "  'for',\n",
              "  'a',\n",
              "  'south',\n",
              "  'carolina',\n",
              "  'that',\n",
              "  '’s',\n",
              "  'almost',\n",
              "  '28',\n",
              "  'percent',\n",
              "  'black',\n",
              "  '(',\n",
              "  'compared',\n",
              "  'to',\n",
              "  '1',\n",
              "  '%',\n",
              "  'in',\n",
              "  'new',\n",
              "  'hampshire',\n",
              "  ')',\n",
              "  'and',\n",
              "  'holds',\n",
              "  'its',\n",
              "  'democratic',\n",
              "  'primary',\n",
              "  'the',\n",
              "  'following',\n",
              "  'saturday',\n",
              "  ':',\n",
              "  '“',\n",
              "  'african',\n",
              "  '-',\n",
              "  'americans',\n",
              "  'who',\n",
              "  'face',\n",
              "  'discrimination',\n",
              "  'in',\n",
              "  'the',\n",
              "  ...],\n",
              " 'title': ['does',\n",
              "  'bernie',\n",
              "  'sanders',\n",
              "  'really',\n",
              "  'want',\n",
              "  'to',\n",
              "  'win',\n",
              "  '?',\n",
              "  'three',\n",
              "  'democratic',\n",
              "  'debate',\n",
              "  'takeaways']}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6c7t2IgJCVnN"
      },
      "source": [
        "MAX_VOCAB_SIZE = 25_000\n",
        "\n",
        "text.build_vocab(train_data, max_size = MAX_VOCAB_SIZE, vectors = \"glove.6B.100d\", unk_init = torch.Tensor.normal_)\n",
        "title.build_vocab(train_data, max_size = MAX_VOCAB_SIZE, vectors = \"glove.6B.100d\", unk_init = torch.Tensor.normal_)\n",
        "label.build_vocab(train_data)"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2BHnHJppCVnN"
      },
      "source": [
        "BATCH_SIZE = 64\n",
        "\n",
        "device = torch.device('cuda')\n",
        "\n",
        "train_iterator, validation_iterator, test_iterator = BucketIterator.splits(\n",
        "    (train_data, validation_data, test_data), \n",
        "    batch_size = BATCH_SIZE,\n",
        "    sort_key = lambda x: x.title,\n",
        "    sort_within_batch = True,\n",
        "    # sort=False,\n",
        "    device = device)"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9clpAr98CVnO"
      },
      "source": [
        "import torch.nn as nn\n",
        "\n",
        "class RNN(nn.Module):\n",
        "    def __init__(self, vocab_size, embedding_dim, hidden_dim, output_dim, n_layers, \n",
        "                    bidirectional, dropout, pad_idx):\n",
        "        super().__init__()\n",
        "\n",
        "        self.embedding = nn.Embedding(vocab_size, embedding_dim, padding_idx = pad_idx)\n",
        "        self.rnn = nn.LSTM(embedding_dim, hidden_dim, num_layers = n_layers, bidirectional=bidirectional, dropout = dropout )\n",
        "        self.fc = nn.Linear(hidden_dim * 2, output_dim)\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "\n",
        "    def forward(self, text, text_lengths):\n",
        "        \n",
        "        #print(text.size())\n",
        "        #text = [sent len, batch size]\n",
        "        embedded = self.dropout(self.embedding(text))\n",
        "        # embedded = [sent len, batch size, emb dim]\n",
        "        \n",
        "        # pack sequence\n",
        "        packed_embedded = nn.utils.rnn.pack_padded_sequence(embedded, text_lengths.to('cpu'), enforce_sorted=False)\n",
        "        packed_output, (hidden, cell) = self.rnn(packed_embedded)\n",
        "\n",
        "        # unpack sequence\n",
        "        output, output_lengths = nn.utils.rnn.pad_packed_sequence(packed_output)\n",
        "\n",
        "        #output = [sent len, batch size, hid dim * num directions]\n",
        "        #output over padding tokens are zero tensors\n",
        "        \n",
        "        #hidden = [num layers * num directions, batch size, hid dim]\n",
        "        #cell = [num layers * num directions, batch size, hid dim]\n",
        "        \n",
        "        #concat the final forward (hidden[-2,:,:]) and backward (hidden[-1,:,:]) hidden layers\n",
        "        #and apply dropout\n",
        "\n",
        "        hidden = self.dropout(torch.cat((hidden[-2,:,:], hidden[-1,:,:]), dim = 1))\n",
        "\n",
        "        #hidden = [batch size, hid dim * num directions]\n",
        "\n",
        "        return self.fc(hidden)"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UHuFbus7CVnO"
      },
      "source": [
        "INPUT_DIM = len(text.vocab)\n",
        "EMBEDDING_DIM = 100\n",
        "HIDDEN_DIM = 256\n",
        "OUTPUT_DIM = 1\n",
        "N_LAYERS = 2\n",
        "BIDIRECTIONAL = True\n",
        "DROPOUT = 0.5\n",
        "PAD_IDX = text.vocab.stoi[text.pad_token]\n",
        "\n",
        "model = RNN(INPUT_DIM, \n",
        "            EMBEDDING_DIM, \n",
        "            HIDDEN_DIM, \n",
        "            OUTPUT_DIM, \n",
        "            N_LAYERS, \n",
        "            BIDIRECTIONAL, \n",
        "            DROPOUT, \n",
        "            PAD_IDX)\n"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jN9-6oAiCVnP",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0cb2811f-da6a-4a41-db79-d4d975bf23a1"
      },
      "source": [
        "def count_parameters(model):\n",
        "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
        "\n",
        "print(f'The model has {count_parameters(model):,} trainable parameters')"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The model has 4,810,857 trainable parameters\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Mh0dpn4SCVnP",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "56458e23-3874-48e9-8dd6-df12f243a41c"
      },
      "source": [
        "pretrained_embeddings = text.vocab.vectors\n",
        "print(pretrained_embeddings.shape)"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.Size([25002, 100])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sefH0pL2CVnQ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6d9b29f2-8ed3-42b4-dfe6-68508777a4c5"
      },
      "source": [
        "model.embedding.weight.data.copy_(pretrained_embeddings)"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[-0.6775,  0.6508, -1.4881,  ..., -0.3913, -0.3616,  0.1976],\n",
              "        [ 0.9480, -0.0378,  0.0487,  ..., -0.9490, -1.3723,  0.6721],\n",
              "        [-0.0382, -0.2449,  0.7281,  ..., -0.1459,  0.8278,  0.2706],\n",
              "        ...,\n",
              "        [-0.3932, -0.1523,  0.3094,  ...,  0.1689,  0.7236, -0.4796],\n",
              "        [ 0.3495, -0.0160, -0.3485,  ..., -0.2744, -0.6759,  0.2178],\n",
              "        [-0.2805,  0.1509,  0.9577,  ...,  0.7749,  0.1199, -0.6552]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "amv-CjtZCVnQ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d1b89622-4650-477b-eec8-85b24a875c5d"
      },
      "source": [
        "UNK_IDX = text.vocab.stoi[text.unk_token]\n",
        "\n",
        "model.embedding.weight.data[UNK_IDX] = torch.zeros(EMBEDDING_DIM)\n",
        "model.embedding.weight.data[PAD_IDX] = torch.zeros(EMBEDDING_DIM)\n",
        "\n",
        "print(model.embedding.weight.data)"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
            "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
            "        [-0.0382, -0.2449,  0.7281,  ..., -0.1459,  0.8278,  0.2706],\n",
            "        ...,\n",
            "        [-0.3932, -0.1523,  0.3094,  ...,  0.1689,  0.7236, -0.4796],\n",
            "        [ 0.3495, -0.0160, -0.3485,  ..., -0.2744, -0.6759,  0.2178],\n",
            "        [-0.2805,  0.1509,  0.9577,  ...,  0.7749,  0.1199, -0.6552]])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_YoLGl23CVnQ"
      },
      "source": [
        "import torch.optim as optim\n",
        "\n",
        "optimizer = optim.Adam(model.parameters())"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CBfXzMkdCVnR"
      },
      "source": [
        "criterion = nn.BCEWithLogitsLoss()\n",
        "\n",
        "model = model.to(device)\n",
        "criterion = criterion.to(device)"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9-xs-Mp7CVnR"
      },
      "source": [
        "def binary_accuracy(preds, label):\n",
        "    rounded_preds = torch.round(torch.sigmoid(preds))\n",
        "    correct = (rounded_preds == label).float()\n",
        "    acc = correct.sum()/len(correct)\n",
        "    return acc"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TktKAH3gCVnR"
      },
      "source": [
        "def train(model, iterator, optimizer, criterion):\n",
        "    epoch_loss = 0\n",
        "    epoch_acc = 0\n",
        "\n",
        "    model.train()\n",
        "\n",
        "    for batch in iterator:\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        text, text_lengths = batch.text\n",
        "        # print(\"-------batch.text is: -------\")\n",
        "        # print(batch.text)\n",
        "        predictions = model(text, text_lengths).squeeze(1)\n",
        "\n",
        "        loss = criterion(predictions, batch.label)\n",
        "\n",
        "        acc = binary_accuracy(predictions, batch.label)\n",
        "\n",
        "        loss.backward()\n",
        "\n",
        "        optimizer.step()\n",
        "\n",
        "        epoch_loss += loss.item()\n",
        "        epoch_acc += acc.item()\n",
        "    \n",
        "    return epoch_loss/len(iterator), epoch_acc/len(iterator)"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9U-Y69n-CVnS"
      },
      "source": [
        "def evaluate(model, iterator, criterion):\n",
        "    epoch_loss = 0\n",
        "    epoch_acc = 0\n",
        "\n",
        "    model.eval()\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for batch in iterator:\n",
        "            text, text_lengths = batch.text\n",
        "\n",
        "            predictions = model(text, text_lengths).squeeze(1)\n",
        "\n",
        "            loss = criterion(predictions, batch.label)\n",
        "\n",
        "            acc = binary_accuracy(predictions, batch.label)\n",
        "\n",
        "            epoch_loss += loss.item()\n",
        "            epoch_acc += acc.item()\n",
        "    return epoch_loss/len(iterator), epoch_acc/len(iterator)"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rjkm6ls2CVnS"
      },
      "source": [
        "import time\n",
        "\n",
        "def epoch_time(start_time, end_time):\n",
        "    elapsed_time = end_time - start_time\n",
        "    elasped_mins = int(elapsed_time / 60)\n",
        "    elapsed_secs = int(elapsed_time - (elasped_mins * 60))\n",
        "\n",
        "    return elasped_mins, elapsed_secs"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CYJNn1qPCVnT"
      },
      "source": [
        "N_EPOCHS = 5\n",
        "\n",
        "best_validation_loss = float('inf')"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "pixiedust": {
          "displayParams": {}
        },
        "id": "M8GtScmcCVnT",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5bea7a32-aef8-4b7f-c24a-bc26d439864e"
      },
      "source": [
        "#%%pixie_debugger\n",
        "for epoch in range(N_EPOCHS):\n",
        "    start_time = time.time()\n",
        "\n",
        "    train_loss, train_acc = train(model, train_iterator, optimizer, criterion)\n",
        "    validation_loss, validation_acc = evaluate(model, validation_iterator, criterion)\n",
        "\n",
        "    end_time = time.time()\n",
        "\n",
        "    epoch_mins, epoch_secs = epoch_time(start_time, end_time)\n",
        "\n",
        "    if validation_loss < best_validation_loss:\n",
        "        best_validation_loss = validation_loss\n",
        "        torch.save(model.state_dict(), 'LSTM-Model.pt')\n",
        "    \n",
        "    print(f'Epoch: {epoch+1:02} | Epoch Time: {epoch_mins}m {epoch_secs}s')\n",
        "    print(f'\\tTrain Loss: {train_loss:.3f} | Train Acc: {train_acc*100:.2f}%')\n",
        "    print(f'\\Validation Loss: {validation_loss:.3f} | Validation Acc: {validation_acc*100:.2f}%')"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch: 01 | Epoch Time: 1m 20s\n",
            "\tTrain Loss: 0.413 | Train Acc: 81.18%\n",
            "\\Validation Loss: 0.145 | Validation Acc: 93.89%\n",
            "Epoch: 02 | Epoch Time: 1m 20s\n",
            "\tTrain Loss: 0.140 | Train Acc: 94.62%\n",
            "\\Validation Loss: 0.147 | Validation Acc: 94.43%\n",
            "Epoch: 03 | Epoch Time: 1m 20s\n",
            "\tTrain Loss: 0.170 | Train Acc: 93.65%\n",
            "\\Validation Loss: 0.188 | Validation Acc: 95.75%\n",
            "Epoch: 04 | Epoch Time: 1m 20s\n",
            "\tTrain Loss: 0.132 | Train Acc: 94.95%\n",
            "\\Validation Loss: 0.151 | Validation Acc: 94.41%\n",
            "Epoch: 05 | Epoch Time: 1m 20s\n",
            "\tTrain Loss: 0.101 | Train Acc: 96.49%\n",
            "\\Validation Loss: 0.114 | Validation Acc: 96.61%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8Gz4xttoCVnU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b4648dc9-84a3-4114-8d9c-db338247f8ed"
      },
      "source": [
        "#'''\n",
        "model.load_state_dict(torch.load('LSTM-Model.pt'))\n",
        "\n",
        "test_loss, test_acc = evaluate(model, test_iterator, criterion)\n",
        "\n",
        "print(f'Test loss: {test_loss:.3f} | Test Acc: {test_acc*100:.2f}%')\n",
        "#'''"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Test loss: 0.087 | Test Acc: 96.70%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O62hPdXUCVnU"
      },
      "source": [
        "\n",
        "import spacy\n",
        "nlp = spacy.load('en_core_web_sm')\n",
        "\n",
        "def predict_sentiment(model, sentence):\n",
        "    model.eval()\n",
        "    tokenized = [tok.text for tok in nlp.tokenizer(sentence)]\n",
        "    indexed = [text.vocab.stoi[t] for t in tokenized]\n",
        "    length = [len(indexed)]\n",
        "    tensor = torch.LongTensor(indexed).to(device)\n",
        "    tensor = tensor.unsqueeze(1)\n",
        "    length_tensor = torch.LongTensor(length)\n",
        "    prediction = torch.sigmoid(model(tensor, length_tensor))\n",
        "    return prediction.item()\n",
        "\n"
      ],
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZcT7gRRhCVnU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dc0aa865-d6d8-4c1f-c7fb-2929085a8f85"
      },
      "source": [
        "#'''\n",
        "user_inputted_text = input(\"Copy Paste the Text of an Article and we will predict if it is fake or real:\")\n",
        "predict_sentiment(model, user_inputted_text)\n",
        "#'''"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Copy Paste the Text of an Article and we will predict if it is fake or real:Junior Congresswoman Alexandra Ocasio-Cortez has made a lot of waves recently with her Green New Deal nonsense and child-like proposals and speeches.  Well, it’s no different this afternoon as the political pixie announced her intention to draft legislation banning motorcycles from use in the United States of America.   Both Clay and Jax Teller take time off from their busy schedule of runnin’ guns, lovin’ women, and threatening Henry Rollins to address the issue. The Senorita of Socialism threw out all manner of statistics regarding deadly accidents and injuries, relaxed traffic rules and tolls for bikers, as well as a not-so-veiled jab at a core demographic of President Trump’s supporters :  “Besides like, what I just said?  A lot of these like, motorcycle people, okay, they’re like : ‘Ooh, look at me, I’m all old and fat and tough and I voted for Trump and smell like wet dog.’  And I’m supposed to slow my Prius down so you can like, noise pollute past everyone?  I mean some of us have a nail appointment, people.”  Opposing the ban, spokesman and leader of “Bikers For Trump”, Clee Torres, also gave a statement to the press, expressing his, and his organization’s views :  “I don’t know where they found this little girl with the cute little mouth, but ain’t nobody taking away our hogs.  President Trump is the best damn thing to happen to this country since Zima.”   Getting drunk on Zima is kinda like making love to a pillow – I mean, yeah, it works, but you ain’t gonna want to tell anyone about it.   Torres added that Bikers For Trump would hold a protest against the proposal with a million motorcycle convoy in Washington, previous incarnations of which have drawn tens of participants.  Cortez may want to get herself back behind the bar where her little Punky Brewster act can make her some tips.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.9954521059989929"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f34VNWekaU3D"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}